{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from QAmodel import *\n",
    "from transformers import AutoConfig,AutoTokenizer\n",
    "from datasets import load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing QAModelTEST: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing QAModelTEST from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing QAModelTEST from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of QAModelTEST were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['lstm.weight_ih_l0', 'lstm.weight_hh_l0', 'lstm.bias_ih_l0', 'lstm.bias_hh_l0', 'linear.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_NAME='klue/bert-base'\n",
    "config = AutoConfig.from_pretrained(MODEL_NAME)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = QAModelTEST.from_pretrained(MODEL_NAME)\n",
    "model.resize_token_embeddings(32002)\n",
    "model.load_state_dict(torch.load('/opt/ml/input/code/models/train_dataset/pytorch_model.bin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = load_from_disk('/opt/ml/input/data/train_dataset')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "q=train_dataset['question']\n",
    "c=train_dataset['context']\n",
    "tokenized_q=tokenizer(q,max_length=256,padding='max_length',return_tensors=\"pt\",truncation=True)\n",
    "tokenized_c=tokenizer(c,max_length=256,padding='max_length',return_tensors=\"pt\",truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset={'input_ids':tokenized_c['input_ids'],\n",
    "        'token_type_ids':tokenized_c['token_type_ids'],\n",
    "        'attention_mask':tokenized_c['attention_mask'],\n",
    "        'q_input_ids':tokenized_q['input_ids'],\n",
    "        'q_token_type_ids':tokenized_q['token_type_ids'],\n",
    "        'q_attention_mask':tokenized_q['attention_mask']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=model(**dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -2.2614,  -9.1939, -11.2535, -11.7342, -12.1804, -12.1781, -12.3500,\n",
       "         -12.2817, -12.2950, -12.3327, -12.3634, -12.2746, -12.3827, -12.2856,\n",
       "         -12.3235, -12.2164, -12.1898, -11.4985, -12.4647, -12.4661, -12.4635,\n",
       "         -12.4683, -12.4714, -12.4665, -12.4722, -12.4441, -12.4583, -12.4666,\n",
       "         -12.4635, -12.4645, -12.4683, -12.4620, -12.4629, -12.4575, -12.4640,\n",
       "         -12.4658, -12.4659, -12.4697, -12.4449, -12.4648, -12.4624, -12.4640,\n",
       "         -12.4652, -12.4631, -12.4686, -12.4653, -12.4656, -12.4615, -12.4650,\n",
       "         -12.4633, -12.4691, -12.4684, -12.4662, -12.4680, -12.4634, -12.4612,\n",
       "         -12.4635, -12.4630, -12.4644, -12.4614, -12.4647, -12.4408, -12.4608,\n",
       "         -12.4686, -12.4675, -12.4683, -12.4703, -12.4655, -12.4697, -12.4667,\n",
       "         -12.4670, -12.4715, -12.4650, -12.4662, -12.4672, -12.4616, -12.4664,\n",
       "         -12.4664, -12.4652, -12.4669, -12.4630, -12.4662, -12.4681, -12.4640,\n",
       "         -12.4705, -12.4657, -12.4631, -12.4651, -12.4624, -12.4638, -12.4665,\n",
       "         -12.4642, -12.4654, -12.4614, -12.4673, -12.4655, -12.4689, -12.4701,\n",
       "         -12.4708, -12.4682, -12.4696, -12.4667, -12.4647, -12.4692, -12.4662,\n",
       "         -12.4688, -12.4651, -12.4659, -12.4622, -12.4614, -12.4665, -12.4655,\n",
       "         -12.4689, -12.4674, -12.4662, -12.4687, -12.4658, -12.4702, -12.4698,\n",
       "         -12.4669, -12.4693, -12.4638, -12.4453, -12.4634, -12.4636, -12.4692,\n",
       "         -12.4656, -12.4691, -12.4635, -12.4631, -12.4656, -12.4667, -12.4672,\n",
       "         -12.4679, -12.4662, -12.4608, -12.4640, -12.4602, -12.4635, -12.4618,\n",
       "         -12.4628, -12.4644, -12.4610, -12.4625, -12.4642, -12.4632, -12.4697,\n",
       "         -12.4697, -12.4700, -12.4707, -12.4669, -12.4697, -12.4635, -12.4662,\n",
       "         -12.4685, -12.4653, -12.4700, -12.4664, -12.4675, -12.4639, -12.4653,\n",
       "         -12.4670, -12.4680, -12.4708, -12.4470, -12.4693, -12.4678, -12.4650,\n",
       "         -12.4707, -12.4670, -12.4699, -12.4673, -12.4674, -12.4701, -12.4637,\n",
       "         -12.4661, -12.4663, -12.4691, -12.4691, -12.4699, -12.4727, -12.4696,\n",
       "         -12.4712, -12.4470, -12.4677, -12.4707, -12.4676, -12.4730, -12.4683,\n",
       "         -12.4692, -12.4653, -12.4644, -12.4655, -12.4632, -12.4676, -12.4631,\n",
       "         -12.4678, -12.4648, -12.4667, -12.4675, -12.4662, -12.4699, -12.4695,\n",
       "         -12.4721, -12.4688, -12.4700, -12.4699, -12.4653, -12.4710, -12.4690,\n",
       "         -12.4693, -12.4689, -12.4716, -12.4665, -12.4653, -12.4693, -12.4668,\n",
       "         -12.4512, -12.4694, -12.4696, -12.4700, -12.4674, -12.4689, -12.4726,\n",
       "         -12.4688, -12.4717, -12.4732, -12.4675, -12.4668, -12.4683, -12.4627,\n",
       "         -12.4678, -12.4660, -12.4657, -12.4679, -12.4608, -12.4656, -12.4447,\n",
       "         -12.4663, -12.4695, -12.4719, -12.4714, -12.4680, -12.4731, -12.4699,\n",
       "         -12.4745, -12.4740, -12.4716, -12.4728, -12.4679, -12.4697, -12.4676,\n",
       "         -12.4683, -12.4681, -12.4697, -12.4752]], grad_fn=<CloneBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[1].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "linear=nn.Linear(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8088,  0.2733],\n",
       "        [ 0.9658, -0.0968],\n",
       "        [ 0.6342,  0.6846]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.randn([3,1])\n",
    "linear(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
